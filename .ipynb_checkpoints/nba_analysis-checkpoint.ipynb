{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca419b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from pandas import json_normalize\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (mean_absolute_error, mean_squared_error,\n",
    "                             ndcg_score, r2_score)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b1f5945",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEASON = 2022\n",
    "LAST_N_SEASONS = 3\n",
    "RANDOM_SEED = 12345\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "COLLECTION_PLAYER = \"player\"\n",
    "COLLECTION_TEAM = \"team\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f49916e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                team_id  season conference   \n",
      "30    https://www.basketball-reference.com/teams/DAL...    2022       West  \\\n",
      "31    https://www.basketball-reference.com/teams/PHI...    2022       East   \n",
      "32    https://www.basketball-reference.com/teams/HOU...    2022       West   \n",
      "33    https://www.basketball-reference.com/teams/TOR...    2022       East   \n",
      "34    https://www.basketball-reference.com/teams/NOP...    2022       West   \n",
      "...                                                 ...     ...        ...   \n",
      "1598  https://www.basketball-reference.com/teams/MNL...    1950       East   \n",
      "1599  https://www.basketball-reference.com/teams/SYR...    1950       East   \n",
      "1600  https://www.basketball-reference.com/teams/INO...    1950       West   \n",
      "1601  https://www.basketball-reference.com/teams/AND...    1950       West   \n",
      "1602  https://www.basketball-reference.com/teams/BLB...    1950       East   \n",
      "\n",
      "        FG   FGA    FG%    3P   3PA    3P%    2P  ...    L1YP    L3YP    L6YP   \n",
      "30    39.3  85.1  0.461  13.1  37.4  0.350  26.2  ...  0.1875  0.3125  0.3750  \\\n",
      "31    39.4  84.5  0.466  11.6  31.8  0.364  27.8  ...  0.4375  0.8750  1.1875   \n",
      "32    39.4  86.4  0.456  13.5  38.7  0.349  25.9  ...  0.0000  0.6875  1.8125   \n",
      "33    40.6  91.3  0.445  11.9  34.2  0.349  28.7  ...  0.0000  1.4375  2.5625   \n",
      "34    40.2  88.0  0.457  10.6  32.1  0.332  29.5  ...  0.0000  0.0000  0.3125   \n",
      "...    ...   ...    ...   ...   ...    ...   ...  ...     ...     ...     ...   \n",
      "1598  31.5  85.8  0.367   NaN   NaN    NaN  31.5  ...  0.0000  0.0000  0.0000   \n",
      "1599  29.2  82.4  0.354   NaN   NaN    NaN  29.2  ...  0.0000  0.0000  0.0000   \n",
      "1600  31.0  82.5  0.375   NaN   NaN    NaN  31.0  ...  0.0000  0.0000  0.0000   \n",
      "1601  30.4  97.7  0.311   NaN   NaN    NaN  30.4  ...  0.0000  0.0000  0.0000   \n",
      "1602  25.2  81.1  0.310   NaN   NaN    NaN  25.2  ...  0.0000  0.0000  0.0000   \n",
      "\n",
      "       L10YP  count_playoff_games  count_champion  sum_mvp_shares   \n",
      "30    0.6250                159.0             0.0           0.240  \\\n",
      "31    1.6250                508.0             3.0           4.288   \n",
      "32    2.6250                  0.0             0.0           0.000   \n",
      "33    2.7500                194.0             3.0           0.017   \n",
      "34    0.3125                155.0             0.0           0.000   \n",
      "...      ...                  ...             ...             ...   \n",
      "1598  0.0000                  0.0             0.0           0.000   \n",
      "1599  0.0000                  0.0             0.0           0.000   \n",
      "1600  0.0000                  0.0             0.0           0.000   \n",
      "1601  0.0000                  0.0             0.0           0.000   \n",
      "1602  0.0000                  0.0             0.0           0.000   \n",
      "\n",
      "      sum_dpoy_shares  count_all_nba  count_all_defensive  \n",
      "30              0.000            2.0                  0.0  \n",
      "31              1.067           13.0                  7.0  \n",
      "32              0.000            0.0                  0.0  \n",
      "33              0.000            1.0                  0.0  \n",
      "34              0.000            0.0                  0.0  \n",
      "...               ...            ...                  ...  \n",
      "1598            0.000            0.0                  0.0  \n",
      "1599            0.000            0.0                  0.0  \n",
      "1600            0.000            0.0                  0.0  \n",
      "1601            0.000            0.0                  0.0  \n",
      "1602            0.000            0.0                  0.0  \n",
      "\n",
      "[1573 rows x 93 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data.csv\", encoding=\"utf-8-sig\")\n",
    "\n",
    "\n",
    "'''\n",
    "df.drop([\"team_id\", \"champion\"],\n",
    "        axis=\"columns\",  \n",
    "        inplace=True)\n",
    "df['Rk_Conference'] = df.groupby(['season', 'conference'])['W'].rank(\"min\", ascending=False)\n",
    "df['Rk_Conference'] = df['Rk_Conference'] + df['Rk_Season']\n",
    "df['Rk_Conference'] = df.groupby(['season', 'conference'])['Rk_Conference'].rank(\"min\", ascending=True)\n",
    "del df['conference']\n",
    "\n",
    "df['Top_3_Conference'] = df['Rk_Conference'].apply(lambda cell: True if cell <=3 else False)\n",
    "df.to_csv(\"data_edit.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "'''\n",
    "df = df[df['season'] <= MAX_SEASON]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "406e2b66",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(features, labels, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Convert the data to PyTorch tensors\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m y_train \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y_train, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     13\u001b[0m X_test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(X_test, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "# Select the features\n",
    "features = df.drop('champion', axis=1).values\n",
    "\n",
    "# Select the labels\n",
    "labels = df['champion'].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3658904",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(22, 32)\n",
    "        self.fc2 = nn.Linear(32, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "net = Net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4c2a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174ec1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    output = net(X_train)\n",
    "    loss = criterion(output, y_train.view(-1, 1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{1000}, Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7be42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = net(X_test)\n",
    "    predictions = (output > 0.5).float()\n",
    "    accuracy = (predictions == y_test.view(-1, 1)).float().mean()\n",
    "    print(f\"Accuracy: {accuracy.item():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
