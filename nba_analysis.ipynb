{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca419b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from pandas import json_normalize\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (mean_absolute_error, mean_squared_error,\n",
    "                             ndcg_score, r2_score)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b1f5945",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEASON = 2022\n",
    "LAST_N_SEASONS = 3\n",
    "RANDOM_SEED = 12345\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "COLLECTION_PLAYER = \"player\"\n",
    "COLLECTION_TEAM = \"team\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9f49916e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                team_id  season conference   \n",
      "30    https://www.basketball-reference.com/teams/DAL...    2022       West  \\\n",
      "31    https://www.basketball-reference.com/teams/PHI...    2022       East   \n",
      "32    https://www.basketball-reference.com/teams/HOU...    2022       West   \n",
      "33    https://www.basketball-reference.com/teams/TOR...    2022       East   \n",
      "34    https://www.basketball-reference.com/teams/NOP...    2022       West   \n",
      "...                                                 ...     ...        ...   \n",
      "1598  https://www.basketball-reference.com/teams/MNL...    1950       East   \n",
      "1599  https://www.basketball-reference.com/teams/SYR...    1950       East   \n",
      "1600  https://www.basketball-reference.com/teams/INO...    1950       West   \n",
      "1601  https://www.basketball-reference.com/teams/AND...    1950       West   \n",
      "1602  https://www.basketball-reference.com/teams/BLB...    1950       East   \n",
      "\n",
      "        FG   FGA    FG%    3P   3PA    3P%    2P  ...    L1YP    L3YP    L6YP   \n",
      "30    39.3  85.1  0.461  13.1  37.4  0.350  26.2  ...  0.1875  0.3125  0.3750  \\\n",
      "31    39.4  84.5  0.466  11.6  31.8  0.364  27.8  ...  0.4375  0.8750  1.1875   \n",
      "32    39.4  86.4  0.456  13.5  38.7  0.349  25.9  ...  0.0000  0.6875  1.8125   \n",
      "33    40.6  91.3  0.445  11.9  34.2  0.349  28.7  ...  0.0000  1.4375  2.5625   \n",
      "34    40.2  88.0  0.457  10.6  32.1  0.332  29.5  ...  0.0000  0.0000  0.3125   \n",
      "...    ...   ...    ...   ...   ...    ...   ...  ...     ...     ...     ...   \n",
      "1598  31.5  85.8  0.367   NaN   NaN    NaN  31.5  ...  0.0000  0.0000  0.0000   \n",
      "1599  29.2  82.4  0.354   NaN   NaN    NaN  29.2  ...  0.0000  0.0000  0.0000   \n",
      "1600  31.0  82.5  0.375   NaN   NaN    NaN  31.0  ...  0.0000  0.0000  0.0000   \n",
      "1601  30.4  97.7  0.311   NaN   NaN    NaN  30.4  ...  0.0000  0.0000  0.0000   \n",
      "1602  25.2  81.1  0.310   NaN   NaN    NaN  25.2  ...  0.0000  0.0000  0.0000   \n",
      "\n",
      "       L10YP  count_playoff_games  count_champion  sum_mvp_shares   \n",
      "30    0.6250                159.0             0.0           0.240  \\\n",
      "31    1.6250                508.0             3.0           4.288   \n",
      "32    2.6250                  0.0             0.0           0.000   \n",
      "33    2.7500                194.0             3.0           0.017   \n",
      "34    0.3125                155.0             0.0           0.000   \n",
      "...      ...                  ...             ...             ...   \n",
      "1598  0.0000                  0.0             0.0           0.000   \n",
      "1599  0.0000                  0.0             0.0           0.000   \n",
      "1600  0.0000                  0.0             0.0           0.000   \n",
      "1601  0.0000                  0.0             0.0           0.000   \n",
      "1602  0.0000                  0.0             0.0           0.000   \n",
      "\n",
      "      sum_dpoy_shares  count_all_nba  count_all_defensive  \n",
      "30              0.000            2.0                  0.0  \n",
      "31              1.067           13.0                  7.0  \n",
      "32              0.000            0.0                  0.0  \n",
      "33              0.000            1.0                  0.0  \n",
      "34              0.000            0.0                  0.0  \n",
      "...               ...            ...                  ...  \n",
      "1598            0.000            0.0                  0.0  \n",
      "1599            0.000            0.0                  0.0  \n",
      "1600            0.000            0.0                  0.0  \n",
      "1601            0.000            0.0                  0.0  \n",
      "1602            0.000            0.0                  0.0  \n",
      "\n",
      "[1573 rows x 93 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data.csv\", encoding=\"utf-8-sig\")\n",
    "\n",
    "\n",
    "'''\n",
    "df.drop([\"team_id\", \"champion\"],\n",
    "        axis=\"columns\",  \n",
    "        inplace=True)\n",
    "df['Rk_Conference'] = df.groupby(['season', 'conference'])['W'].rank(\"min\", ascending=False)\n",
    "df['Rk_Conference'] = df['Rk_Conference'] + df['Rk_Season']\n",
    "df['Rk_Conference'] = df.groupby(['season', 'conference'])['Rk_Conference'].rank(\"min\", ascending=True)\n",
    "del df['conference']\n",
    "\n",
    "df['Top_3_Conference'] = df['Rk_Conference'].apply(lambda cell: True if cell <=3 else False)\n",
    "df.to_csv(\"data_edit.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "'''\n",
    "df = df[df['season'] <= MAX_SEASON]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6e2b0fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      season    FG   FGA    FG%    3P   3PA    3P%    2P   2PA    2P%  ...   \n",
      "30      2022  39.3  85.1  0.461  13.1  37.4  0.350  26.2  47.8  0.548  ...  \\\n",
      "31      2022  39.4  84.5  0.466  11.6  31.8  0.364  27.8  52.7  0.527  ...   \n",
      "32      2022  39.4  86.4  0.456  13.5  38.7  0.349  25.9  47.7  0.543  ...   \n",
      "33      2022  40.6  91.3  0.445  11.9  34.2  0.349  28.7  57.1  0.503  ...   \n",
      "34      2022  40.2  88.0  0.457  10.6  32.1  0.332  29.5  55.9  0.528  ...   \n",
      "...      ...   ...   ...    ...   ...   ...    ...   ...   ...    ...  ...   \n",
      "1219    1980  44.1  90.1  0.490   2.0   5.1  0.384  42.1  84.9  0.496  ...   \n",
      "1220    1980  46.4  93.6  0.496   0.5   2.3  0.220  45.9  91.2  0.503  ...   \n",
      "1221    1980  46.5  98.1  0.474   0.4   2.3  0.193  46.0  95.8  0.481  ...   \n",
      "1222    1980  47.5  89.9  0.529   0.2   1.2  0.200  47.3  88.6  0.534  ...   \n",
      "1223    1980  43.0  87.3  0.492   0.3   1.5  0.216  42.6  85.7  0.497  ...   \n",
      "\n",
      "          L1YP      L3YP      L6YP     L10YP  count_playoff_games   \n",
      "30    0.187500  0.312500  0.375000  0.625000                159.0  \\\n",
      "31    0.437500  0.875000  1.187500  1.625000                508.0   \n",
      "32    0.000000  0.687500  1.812500  2.625000                  0.0   \n",
      "33    0.000000  1.437500  2.562500  2.750000                194.0   \n",
      "34    0.000000  0.000000  0.312500  0.312500                155.0   \n",
      "...        ...       ...       ...       ...                  ...   \n",
      "1219  0.000000  0.357143  2.857143  3.857143                  0.0   \n",
      "1220  0.000000  0.142857  0.642857  3.976190                  0.0   \n",
      "1221  0.000000  0.071429  0.571429  0.571429                  0.0   \n",
      "1222  0.250000  0.607143  0.690476  3.773810                  0.0   \n",
      "1223  0.416667  1.559524  1.642857  1.976190                  0.0   \n",
      "\n",
      "      count_champion  sum_mvp_shares  sum_dpoy_shares  count_all_nba   \n",
      "30               0.0           0.240            0.000            2.0  \\\n",
      "31               3.0           4.288            1.067           13.0   \n",
      "32               0.0           0.000            0.000            0.0   \n",
      "33               3.0           0.017            0.000            1.0   \n",
      "34               0.0           0.000            0.000            0.0   \n",
      "...              ...             ...              ...            ...   \n",
      "1219             0.0           0.000            0.000            0.0   \n",
      "1220             0.0           0.000            0.000            0.0   \n",
      "1221             0.0           0.000            0.000            0.0   \n",
      "1222             0.0           0.000            0.000            0.0   \n",
      "1223             0.0           0.000            0.000            0.0   \n",
      "\n",
      "      count_all_defensive  \n",
      "30                    0.0  \n",
      "31                    7.0  \n",
      "32                    0.0  \n",
      "33                    0.0  \n",
      "34                    0.0  \n",
      "...                   ...  \n",
      "1219                  0.0  \n",
      "1220                  0.0  \n",
      "1221                  0.0  \n",
      "1222                  0.0  \n",
      "1223                  0.0  \n",
      "\n",
      "[1165 rows x 90 columns]\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(['conference', 'team_id','name'], axis=1)\n",
    "df = df.dropna()\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "406e2b66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Select the features\n",
    "features = df.drop('champion', axis=1).apply(pd.to_numeric, errors='coerce').dropna().values\n",
    "\n",
    "# Select the labels\n",
    "labels = df['champion'].values\n",
    "\n",
    "# Make sure they are not objects\n",
    "features = features.astype(np.float32)\n",
    "labels = labels.astype(np.float32)\n",
    "\n",
    "eighty_percent = int(features.shape[0] * 0.8)\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "print(type(X_train))\n",
    "# Convert the data to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d4cede94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1165, 89) (1165,)\n",
      "float32 float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(features.shape, labels.shape)\n",
    "print(features.dtype, labels.dtype)\n",
    "\n",
    "features.astype(np.float32)\n",
    "labels.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f3658904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TrainTest:\n",
    "\n",
    "#     no_grad = torch.no_grad\n",
    "\n",
    "#     def fit(self, data):\n",
    "#         ## Training loop\n",
    "#         self.train()        ## Set model into training mode\n",
    "#         ## Iterate over the data batches\n",
    "#         for batch, (inputs, target) in enumerate(data):\n",
    "#             ## In real pytorch, you'd need to set the device\n",
    "#             inputs = inputs.to(self.device)\n",
    "#             target = target.to(self.device)\n",
    "#             ## Erase the gradient history\n",
    "#             self.optimizer.zero_grad()\n",
    "#             ## Do a forward pass on the model\n",
    "#             output = self(inputs)\n",
    "#             ## Compute the loss\n",
    "#             loss = self.loss(output, target)\n",
    "#             ## Run backwards pass from the loss through the previous layers\n",
    "#             ## This will accumulate gradients for the parameters that need to be optimized\n",
    "#             loss.backward()\n",
    "#             ## Perform a single optimization step\n",
    "#             self.optimizer.step()\n",
    "#         return {'loss' : loss}\n",
    "\n",
    "#     def evaluate(self, data):\n",
    "#         ## Set model into \"evaluate\" mode so that the parameters don't get updated\n",
    "#         self.eval()\n",
    "#         total_loss = 0\n",
    "#         ## Cut off the tensor training scope to make sure weights aren't updated\n",
    "#         ## For now, it's torch.no_grad; later, you'll use Tensor.no_grad\n",
    "#         with TrainTest.no_grad():\n",
    "#             for inputs, target in data:\n",
    "#                 ## In real pytorch, you'd need to set the device\n",
    "#                 inputs = inputs.to(self.device)\n",
    "#                 target = target.to(self.device)\n",
    "#                 output = self(inputs)\n",
    "#                 total_loss += self.loss(output, target).item()  # sum up batch loss\n",
    "\n",
    "#         total_loss /= len(data)\n",
    "#         return {'test_loss' : total_loss}\n",
    "        \n",
    "#     def train_test(self, train_data, test_data, epochs=200):\n",
    "#         ## Does both training and validation on a per-epoch basis\n",
    "#         all_stats = []\n",
    "#         for epoch in range(epochs):\n",
    "#             train_stats = self.fit(train_data)\n",
    "#             test_stats = self.evaluate(test_data)\n",
    "#             all_stats += [{**train_stats, **test_stats}]\n",
    "#             print(f'[Epoch {epoch+1}/{epochs}]', all_stats[-1])\n",
    "#         return all_stats\n",
    "\n",
    "# class Regression(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Regression,self).__init__()\n",
    "#         self.fc1 = nn.Linear(89, 32)\n",
    "#         self.fc2 = nn.Linear(32, 32)\n",
    "#         self.fc3 = nn.Linear(32, 1)\n",
    "# #         self.optimizer = torch.optim.SGD(self.parameters(),0.3)\n",
    "# #         self.loss = nn.MSELoss()\n",
    "#         self.device = torch.device(\"cpu\")\n",
    "        \n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = torch.relu(self.fc1(x))\n",
    "#         x = torch.relu(self.fc2(x))\n",
    "#         x = torch.sigmoid(self.fc3(x))\n",
    "#         return x\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(89, 32)\n",
    "        self.fc2 = nn.Linear(32, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "174ec1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000, Loss: 0.0159\n",
      "Epoch 51/1000, Loss: 0.0087\n",
      "Epoch 101/1000, Loss: 0.0058\n",
      "Epoch 151/1000, Loss: 0.0041\n",
      "Epoch 201/1000, Loss: 0.0030\n",
      "Epoch 251/1000, Loss: 0.0022\n",
      "Epoch 301/1000, Loss: 0.0017\n",
      "Epoch 351/1000, Loss: 0.0013\n",
      "Epoch 401/1000, Loss: 0.0011\n",
      "Epoch 451/1000, Loss: 0.0008\n",
      "Epoch 501/1000, Loss: 0.0006\n",
      "Epoch 551/1000, Loss: 0.0003\n",
      "Epoch 601/1000, Loss: 0.0001\n",
      "Epoch 651/1000, Loss: 0.0000\n",
      "Epoch 701/1000, Loss: 0.0000\n",
      "Epoch 751/1000, Loss: 0.0000\n",
      "Epoch 801/1000, Loss: 0.0000\n",
      "Epoch 851/1000, Loss: 0.0000\n",
      "Epoch 901/1000, Loss: 0.0000\n",
      "Epoch 951/1000, Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    output = net(X_train)\n",
    "    loss = criterion(output, y_train.view(-1, 1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{1000}, Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "1a7be42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output = net(X_test)\n",
    "    predictions = (output > 0.5).float()\n",
    "    accuracy = (predictions == y_test.view(-1, 1)).float().mean()\n",
    "    print(f\"Accuracy: {accuracy.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "4b2b6c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "21c6166e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0745,  0.0355,  0.0284,  ..., -0.0910, -0.0211,  0.0005],\n",
      "        [-0.0074,  0.1002, -0.0375,  ...,  0.0559,  0.0405, -0.0742],\n",
      "        [ 0.0160,  0.0062,  0.0026,  ...,  0.0298, -0.0648, -0.0387],\n",
      "        ...,\n",
      "        [ 0.0896, -0.0804,  0.0363,  ..., -0.1030, -0.0590,  0.0319],\n",
      "        [ 0.0397,  0.0838,  0.0240,  ...,  0.0394, -0.0725,  0.0628],\n",
      "        [ 0.0068, -0.0457, -0.0338,  ..., -0.0620,  0.0577, -0.0389]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 6.7995e-02, -8.7668e-02,  1.0141e-01, -6.0563e-02, -3.9870e-02,\n",
      "         6.7667e-02,  8.1813e-02, -3.6084e-02, -5.9940e-02, -9.9603e-02,\n",
      "        -8.8033e-02,  3.5419e-02,  7.0659e-02,  7.8167e-02, -4.8926e-02,\n",
      "        -1.9692e-02,  4.7587e-05,  5.7349e-02,  2.1920e-02, -6.0227e-02,\n",
      "        -6.9172e-02, -7.5796e-02, -5.5496e-02, -6.4445e-02, -6.7224e-02,\n",
      "         1.0398e-01, -4.4453e-02, -8.8217e-02, -6.0865e-02,  5.7918e-02,\n",
      "         9.1616e-02, -7.4160e-02], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1706,  0.1343, -0.0354,  ..., -0.0995, -0.0611,  0.0558],\n",
      "        [-0.0245,  0.0661,  0.1161,  ..., -0.1136,  0.1336, -0.1468],\n",
      "        [-0.0234,  0.0797,  0.0723,  ...,  0.1678,  0.0009,  0.0527],\n",
      "        ...,\n",
      "        [ 0.1651, -0.0138,  0.1406,  ...,  0.1754, -0.0080,  0.1051],\n",
      "        [-0.1139, -0.1441,  0.0125,  ..., -0.0294,  0.1458, -0.1166],\n",
      "        [-0.1212, -0.0355, -0.1428,  ...,  0.0628,  0.1605, -0.1731]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0875, -0.0393,  0.1280, -0.1614,  0.0372, -0.0467,  0.0601, -0.1127,\n",
      "         0.1087,  0.0801, -0.0739, -0.1231,  0.0597,  0.0178, -0.0407, -0.0997,\n",
      "         0.0491,  0.0970,  0.0270, -0.0776,  0.1267, -0.0279,  0.1504,  0.1325,\n",
      "         0.1134,  0.0192,  0.1256, -0.1368,  0.0385, -0.0800,  0.1612, -0.0598],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0300, -0.1064,  0.1297,  0.1508, -0.1420,  0.1690, -0.0924,  0.0949,\n",
      "         -0.1028, -0.0730, -0.1394, -0.1625,  0.1118,  0.0906, -0.1222,  0.0467,\n",
      "         -0.0831, -0.0340,  0.1126,  0.0256, -0.0127, -0.0868,  0.1603,  0.1234,\n",
      "          0.1127, -0.1577,  0.1564, -0.0257,  0.0830,  0.0014,  0.0140, -0.1245]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0341], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load(\"model.pt\"))\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Use the model to make predictions on new data\n",
    "#input = [2021, 39.3, 88.5, 0.444, 13.8, 40.6, 0.339, 25.5, 47.9, 0.532, 16.5, 22.3, 0.74, 9.3, 33.3, 42.6, 23.6, 7.6, 5, 14.7, 19.5, 108.8, 42.7, 89, 0.48, 13.4, 35.2, 0.382, 29.3, 53.9, 0.544, 17.9, 22.8, 0.783, 9.9, 37.7, 47.6, 25.8, 8.5, 5.3, 14.7, 19.3, 116.7, 26.5, 17, 55, 20, 52, -7.9, 0.4, -7.5, 107.1, 114.9, -7.8, 101.4, 0.252, 0.459, 0.553, 0.521, 13, 19.8, 0.187, 0.555, 12.9, 77.1, 0.201, False, 30, 0.236111111, 0.25, 0.222222222, 0.323529412, 0.157894737, 0.428571429, 0.177777778, 0, 0, 0.5, 0.25, False, 0.3125, 1.375, 2.375, 2.625, 0, 0, 0, 0, 0, 0]\n",
    "new_data = torch.tensor([39.3, 88.5, 100, 13.8, -40.6, 0.339, 0, 0, 0.532, 16.5, 22.3, 0.74, -9.3, -33.3, -42.6, -23.6, 7.6, 5, 14.7, 0, 108.8, 42.7, 89, 0.48, 13.4, 0, 0.382, 29.3, 0, 0.544, 17.9, 22.8, 0.783, 9.9, 37.7, 47.6, 25.8, 8.5, 5.3, 14.7, 19.3, 116.7, 26.5, 17, 55, 20, 52, -7.9, 0.4, -7.5, 107.1, 114.9, -7.8, 101.4, 0.252, 0.459, 0.553, 0.521, 13, 19.8, 0.187, 0.555, 12.9, 77.1, 0.201, False, 30, 0.236111111, 0.25, 0.222222222, 0.323529412, 0.157894737, 0.428571429, 0.177777778, 0, 0, 0.5, 0.25, False, 0.3125, 1.375, 2.375, 2.625, 0, 0, 0, 0, 0, 0])\n",
    "output = model(new_data)\n",
    "\n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "51776379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x0000025C793A3040>\n"
     ]
    }
   ],
   "source": [
    "state_dict = model.state_dict()\n",
    "\n",
    "print(state_dict['weight'])\n",
    "print(state_dict['bias'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
